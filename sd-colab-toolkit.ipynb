{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cmz97/stable-diff-playground/blob/main/sd-colab-toolkit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I. Installation"
      ],
      "metadata": {
        "id": "akFjukqz5PbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 1.1 Install Dependencies\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "root_dir = \"/content/\"\n",
        "repo_dir = f\"{root_dir}/sd-scripts\"\n",
        "models_dir = f\"{root_dir}/models\"\n",
        "vaes_dir = f\"{root_dir}/vae\"\n",
        "deps_dir = f\"{root_dir}/deps\"\n",
        "tools_dir = f\"{root_dir}/sd-scripts/tools\"\n",
        "\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "os.makedirs(vaes_dir, exist_ok=True)\n",
        "\n",
        "if not os.path.isdir(repo_dir):\n",
        "  !git clone https://github.com/kohya-ss/sd-scripts\n",
        "\n",
        "os.chdir(repo_dir)\n",
        "\n",
        "#@markdown This will install required Python packages\n",
        "!pip install --upgrade -r requirements.txt\n",
        "!pip install --upgrade --no-cache-dir gdown\n",
        "\n",
        "def ubuntu_deps(url, name, dst):\n",
        "  !wget -q --show-progress {url}\n",
        "  with zipfile.ZipFile(name, 'r') as deps:\n",
        "    deps.extractall(dst)\n",
        "  !dpkg -i {dst}/*\n",
        "  os.remove(name)\n",
        "  shutil.rmtree(dst)\n",
        "ubuntu_deps(\"https://huggingface.co/Linaqruf/fast-repo/resolve/main/deb-libs.zip\", \"deb-libs.zip\", deps_dir)\n",
        "\n"
      ],
      "metadata": {
        "id": "0BicRIFqIjg0",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 1.2. Download Custom Model\n",
        "\n",
        "os.chdir(models_dir)\n",
        "\n",
        "import os\n",
        "\n",
        "#@markdown ### Custom model\n",
        "modelList = []\n",
        "modelUrl = \"\" #@param {'type': 'string'}\n",
        "modelUrl2 = \"\" #@param {'type': 'string'}\n",
        "modelUrl3 = \"\" #@param {'type': 'string'}\n",
        "modelUrl4 = \"\" #@param {'type': 'string'}\n",
        "\n",
        "modelList.extend([modelUrl, \n",
        "                  modelUrl2,\n",
        "                  modelUrl3,\n",
        "                  modelUrl4])\n",
        "\n",
        "def install_aria():\n",
        "  if not os.path.exists('/usr/bin/aria2c'):\n",
        "    !apt install -y -qq aria2\n",
        "\n",
        "def install(url):\n",
        "\n",
        "\n",
        "  if url.startswith(\"https://drive.google.com\"):\n",
        "    !gdown --fuzzy  \"{url}\"\n",
        "  elif url.startswith(\"magnet:?\"):\n",
        "    install_aria()\n",
        "    !aria2c --summary-interval=10 -c -x 10 -k 1M -s 10 \"{url}\"\n",
        "  elif url.startswith(\"https://huggingface.co/\"):\n",
        "    base_name = os.path.basename(url)\n",
        "    if '/blob/' in url:\n",
        "      url = url.replace('/blob/', '/resolve/')\n",
        "\n",
        "    hf_token = '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'\n",
        "    user_header = f\"\\\"Authorization: Bearer {hf_token}\\\"\"\n",
        "    !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {models_dir} -o \"{base_name}\" \"{url}\"\n",
        "  else:\n",
        "    !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {models_dir} -Z \"{url}\"\n",
        "\n",
        "def install_checkpoint():\n",
        "  for customModel in modelList:\n",
        "    install(customModel)\n",
        "\n",
        "install_checkpoint()\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "A2NC0tm8vU-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 1.3. Download VAE\n",
        "os.chdir(vaes_dir)\n",
        "\n",
        "installVae = []\n",
        "#@markdown ### Available VAE\n",
        "#@markdown Select one of the VAEs to download, select `none` for not download VAE:\n",
        "vaeUrl = [\"\", \\\n",
        "          \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/vae/animevae.pt\", \\\n",
        "          \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime.ckpt\", \\\n",
        "          \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\"]\n",
        "vaeList = [\"none\", \\\n",
        "           \"anime.vae.pt\", \\\n",
        "           \"waifudiffusion.vae.pt\", \\\n",
        "           \"stablediffusion.vae.pt\"]\n",
        "vaeName = \"anime.vae.pt\" #@param [\"none\", \"anime.vae.pt\", \"waifudiffusion.vae.pt\", \"stablediffusion.vae.pt\"]\n",
        "\n",
        "installVae.append((vaeName, vaeUrl[vaeList.index(vaeName)]))\n",
        "\n",
        "def install(vae_name, url):\n",
        "  hf_token = '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'\n",
        "  user_header = f\"\\\"Authorization: Bearer {hf_token}\\\"\"\n",
        "  !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {vaes_dir} -o {vae_name} \"{url}\"\n",
        "\n",
        "def install_vae():\n",
        "  if vaeName != \"none\":\n",
        "    for vae in installVae:\n",
        "      install(vae[0], vae[1])\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "install_vae()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "CZJLUBn3MgRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Model Conversion"
      ],
      "metadata": {
        "id": "WDPfF4uc5pd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "%store -r\n",
        "#@title ## 7.2. Model Pruner\n",
        "\n",
        "os.chdir(tools_dir)\n",
        "\n",
        "if not os.path.exists('prune.py'):\n",
        "  !wget https://raw.githubusercontent.com/lopho/stable-diffusion-prune/main/prune.py\n",
        "\n",
        "#@markdown Convert to Float16\n",
        "fp16 = False #@param {'type':'boolean'}\n",
        "#@markdown Use EMA for weights\n",
        "ema = False #@param {'type':'boolean'}\n",
        "#@markdown Strip CLIP weights\n",
        "no_clip = False #@param {'type':'boolean'}\n",
        "#@markdown Strip VAE weights\n",
        "no_vae = False #@param {'type':'boolean'}\n",
        "#@markdown Strip depth model weights\n",
        "no_depth = False #@param {'type':'boolean'}\n",
        "#@markdown Strip UNet weights\n",
        "no_unet = False #@param {'type':'boolean'}\n",
        "\n",
        "input = \"\" #@param {'type' : 'string'}\n",
        "\n",
        "print(f\"Loading model from {input}\")\n",
        "\n",
        "input_path = os.path.dirname(input)\n",
        "base_name = os.path.basename(input)\n",
        "output_name = base_name.split('.')[0]\n",
        "\n",
        "if fp16:\n",
        "    print(\"Converting to float16\")\n",
        "    output_name += '-fp16'\n",
        "if ema:\n",
        "    print(\"Using EMA for weights\")\n",
        "    output_name += '-ema'\n",
        "if no_clip:\n",
        "    print(\"Stripping CLIP weights\")\n",
        "    output_name += '-no-clip'\n",
        "if no_vae:\n",
        "    print(\"Stripping VAE weights\")\n",
        "    output_name += '-no-vae'\n",
        "if no_depth:\n",
        "    print(\"Stripping depth model weights\")\n",
        "    output_name += '-no-depth'\n",
        "if no_unet:\n",
        "    print(\"Stripping UNet weights\")\n",
        "    output_name += '-no-unet'\n",
        "output_name += '-pruned'\n",
        "output_path = os.path.join(input_path, output_name + ('.ckpt' if input.endswith(\".ckpt\") else \".safetensors\"))\n",
        "\n",
        "!python3 prune.py \"{input}\" \\\n",
        "  \"{output_path}\" \\\n",
        "  {'--fp16' if fp16 else ''} \\\n",
        "  {'--ema' if ema else ''} \\\n",
        "  {'--no-clip' if no_clip else ''} \\\n",
        "  {'--no-vae' if no_vae else ''} \\\n",
        "  {'--no-depth' if no_depth else ''} \\\n",
        "  {'--no-unet' if no_unet else ''}\n",
        "\n",
        "print(f\"Saving pruned model to {output_path}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fb3rxuCaSYta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 7.1. Convert Diffusers to Checkpoint\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "os.chdir(tools_dir)\n",
        "\n",
        "#@markdown ### Conversion Config\n",
        "model_to_load = \"\" #@param {'type': 'string'}\n",
        "model_to_save = os.path.splitext(model_to_load)[0]\n",
        "convert = \"checkpoint_to_diffusers\" #@param [\"diffusers_to_checkpoint\", \"checkpoint_to_diffusers\"] {'allow-input': false}\n",
        "v2 = False #@param {type:'boolean'}\n",
        "global_step = 0 #@param {'type': 'number'}\n",
        "epoch = 0 #@param {'type': 'number'}\n",
        "use_safetensors = True #@param {'type': 'boolean'}\n",
        "save_precision = \"--float\" #@param [\"--fp16\",\"--bf16\",\"--float\"] {'allow-input': false}\n",
        "\n",
        "#@markdown Additional option for diffusers\n",
        "feature_extractor = True #@param {'type': 'boolean'}\n",
        "safety_checker = True #@param {'type': 'boolean'}\n",
        "\n",
        "reference_model = \"stabilityai/stable-diffusion-2-1\" if v2 else \"runwayml/stable-diffusion-v1-5\" \n",
        "\n",
        "if convert == \"diffusers_to_checkpoint\":\n",
        "  model_output = f\"{model_to_save}.safetensors\" if use_safetensors else f\"{model_to_save}.ckpt\"\n",
        "  if not model_to_load.endswith(\".ckpt\") or model_to_load.endswith(\".safetensors\"):\n",
        "    !python convert_diffusers20_original_sd.py \\\n",
        "        \"{model_to_load}\" \\\n",
        "        \"{model_output}\" \\\n",
        "        --global_step {global_step} \\\n",
        "        --epoch {epoch} \\\n",
        "        {save_precision}\n",
        "else:    \n",
        "    !python convert_diffusers20_original_sd.py \\\n",
        "        \"{model_to_load}\" \\\n",
        "        \"{model_to_save}\" \\\n",
        "        {\"--fp16\" if save_precision == \"--fp16\" else \"\"} \\\n",
        "        --global_step {global_step} \\\n",
        "        --epoch {epoch} \\\n",
        "        {\"--use_safetensors\" if use_safetensors else \"\"} \\\n",
        "        {\"--v2\" if v2 else \"--v1\"} \\\n",
        "        --reference_model {reference_model} \n",
        "\n",
        "    url1 = \"https://huggingface.co/CompVis/stable-diffusion-safety-checker/resolve/main/preprocessor_config.json\"\n",
        "    url2 = \"https://huggingface.co/CompVis/stable-diffusion-safety-checker/resolve/main/config.json\"\n",
        "    url3 = \"https://huggingface.co/CompVis/stable-diffusion-safety-checker/resolve/main/pytorch_model.bin\"\n",
        "\n",
        "    if feature_extractor == True:\n",
        "      if not os.path.exists(f'{model_to_save}/feature_extractor'):\n",
        "        os.makedirs(f'{model_to_save}/feature_extractor')\n",
        "      \n",
        "      !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d '{model_to_save}/feature_extractor' -o 'preprocessor_config.json' {url1}\n",
        "\n",
        "    if safety_checker == True:\n",
        "      if not os.path.exists(f'{model_to_save}/safety_checker'):\n",
        "        os.makedirs(f'{model_to_save}/safety_checker')\n",
        "      \n",
        "      !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d '{model_to_save}/safety_checker' -o 'config.json' {url2}\n",
        "      !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d '{model_to_save}/safety_checker' -o 'pytorch_model.bin' {url3}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TdCb8_dSSzzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.3. Replace VAE of Existing Model \n",
        "\n",
        "os.chdir(tools_dir)\n",
        "if not os.path.exists('merge_vae.py'):\n",
        "  !wget https://raw.githubusercontent.com/Linaqruf/kohya-trainer/main/tools/merge_vae.py\n",
        "\n",
        "#@markdown You need to input model ends with `.ckpt`, because `.safetensors` model won't work.\n",
        "\n",
        "target_model = \"\" #@param {'type': 'string'}\n",
        "target_vae = \"/content/vae/anime.vae.pt\" #@param {'type': 'string'}\n",
        "use_safetensors = False #@param {type:'boolean'}\n",
        "# get the base file name and directory\n",
        "base_name = os.path.basename(target_model)\n",
        "base_dir = os.path.dirname(target_model)\n",
        "\n",
        "# get the file name without extension\n",
        "file_name = os.path.splitext(base_name)[0]\n",
        "\n",
        "# create the new file name\n",
        "new_file_name = file_name + \"-vae-swapped\"\n",
        "\n",
        "# get the file extension\n",
        "file_ext = os.path.splitext(base_name)[1]\n",
        "\n",
        "# create the output file path\n",
        "output_model = os.path.join(base_dir, new_file_name + file_ext)\n",
        "\n",
        "!python merge_vae.py \\\n",
        "  {target_model} \\\n",
        "  {target_vae} \\\n",
        "  {output_model}\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "g2QfhhlfbGsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.4. Convert CKPT-2-Safetensors\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from safetensors.torch import load_file, save_file\n",
        "from torch import load, save\n",
        "\n",
        "model_path = \"\" #@param {type: 'string'}\n",
        "\n",
        "def is_safetensors(path):\n",
        "  return os.path.splitext(path)[1].lower() == '.safetensors'\n",
        "\n",
        "def convert(model_path):\n",
        "  print(\"Loading model:\", os.path.basename(model_path))\n",
        "  \n",
        "  try:\n",
        "      with torch.no_grad():\n",
        "          print(\"Conversion in progress, please wait...\")\n",
        "          if is_safetensors(model_path):\n",
        "            model = load_file(model_path, device=\"cpu\")\n",
        "          else:\n",
        "            model = load(model_path, map_location=\"cpu\")\n",
        "          \n",
        "          if 'state_dict' in model:\n",
        "            sd = model['state_dict']\n",
        "          else:\n",
        "            sd = model\n",
        "\n",
        "          save_to = \".ckpt\" if is_safetensors(model_path) else \".safetensors\"\n",
        "          output = os.path.splitext(model_path)[0] + save_to\n",
        "\n",
        "          if is_safetensors(model_path):\n",
        "            save(sd, output)\n",
        "          else:\n",
        "            save_file(sd, output)\n",
        "\n",
        "      print(f'Successfully converted {os.path.basename(model_path)} to {os.path.basename(output)}')\n",
        "      print(f'located in this path : {output}')\n",
        "  except Exception as ex:\n",
        "      print(f'ERROR converting {os.path.basename(model_path)}: {ex}')\n",
        "\n",
        "  print('Done!')\n",
        "\n",
        "def main():\n",
        "  convert(model_path)\n",
        "main()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "L8WI17pmnlVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VIII. Deployment"
      ],
      "metadata": {
        "id": "nyIl9BhNXKUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 8.1. Upload Config\n",
        "from huggingface_hub import login\n",
        "from huggingface_hub import HfApi\n",
        "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
        "\n",
        "#@markdown Login to Huggingface Hub \n",
        "#@markdown > Get **your** huggingface `WRITE` token [here](https://huggingface.co/settings/tokens)\n",
        "write_token = \"\" #@param {type:\"string\"}\n",
        "login(write_token, add_to_git_credential=True)\n",
        "\n",
        "api = HfApi()\n",
        "user = api.whoami(write_token)\n",
        "\n",
        "#@markdown Fill this if you want to upload to your organization, or just leave it empty.\n",
        "\n",
        "orgs_name = \"\" #@param{type:\"string\"}\n",
        "\n",
        "#@markdown If your model/dataset repo didn't exist, it will automatically create your repo.\n",
        "model_name = \"\" #@param{type:\"string\"}\n",
        "make_this_model_private = False #@param{type:\"boolean\"}\n",
        "\n",
        "if orgs_name == \"\":\n",
        "  model_repo = user['name']+\"/\"+model_name.strip()\n",
        "else:\n",
        "  model_repo = orgs_name+\"/\"+model_name.strip()\n",
        "\n",
        "if model_name != \"\":\n",
        "  try:\n",
        "      validate_repo_id(model_repo)\n",
        "      api.create_repo(repo_id=model_repo, \n",
        "                      private=make_this_model_private)\n",
        "      print(\"Model Repo didn't exists, creating repo\")\n",
        "      print(\"Model Repo: \",model_repo,\"created!\\n\")\n",
        "\n",
        "  except HfHubHTTPError as e:\n",
        "      print(f\"Model Repo: {model_repo} exists, skipping create repo\\n\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QTXsM170GUpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.2. Upload with Huggingface Hub"
      ],
      "metadata": {
        "id": "Fuxghk8MnG6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 8.2.1. Upload Model\n",
        "from huggingface_hub import HfApi\n",
        "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
        "from pathlib import Path\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "#@markdown This will be uploaded to model repo\n",
        "\n",
        "model_path = \"/content/models/anything-v3-1.ckpt\" #@param {type :\"string\"}\n",
        "path_in_repo = \"\" #@param {type :\"string\"}\n",
        "revision = \"\" #@param {type :\"string\"}\n",
        "if revision:\n",
        "  api.create_branch(repo_id=model_repo, \n",
        "                branch=revision, \n",
        "                exist_ok=True)\n",
        "else:\n",
        "  revision = \"main\"\n",
        "#@markdown Other Information\n",
        "commit_message = \"\" #@param {type :\"string\"}\n",
        "\n",
        "\n",
        "if os.path.exists(model_path):\n",
        "  vae_exists = os.path.exists(os.path.join(model_path, 'vae'))\n",
        "  unet_exists = os.path.exists(os.path.join(model_path, 'unet'))\n",
        "  text_encoder_exists = os.path.exists(os.path.join(model_path, 'text_encoder'))\n",
        "    \n",
        "def upload_model(model_paths, is_folder :bool, commit_message):\n",
        "  path_obj = Path(model_paths)\n",
        "  trained_model = path_obj.parts[-1]\n",
        "  \n",
        "  if path_in_repo:\n",
        "    trained_model = path_in_repo\n",
        "    \n",
        "  if is_folder == True:\n",
        "    print(f\"Uploading {trained_model} to https://huggingface.co/\"+model_repo)\n",
        "    print(f\"Please wait...\")\n",
        "\n",
        "    if vae_exists and unet_exists and text_encoder_exists:\n",
        "      if not commit_message:\n",
        "        commit_message = f\"feat: upload diffusers version of {trained_model}\"\n",
        "\n",
        "      api.upload_folder(\n",
        "          folder_path=model_paths,\n",
        "          repo_id=model_repo,\n",
        "          revision=revision,\n",
        "          commit_message=commit_message,\n",
        "          ignore_patterns=\".ipynb_checkpoints\"\n",
        "          )\n",
        "    \n",
        "    else:\n",
        "      if not commit_message:\n",
        "        commit_message = f\"feat: upload {trained_model} checkpoint folder\"\n",
        "\n",
        "      api.upload_folder(\n",
        "          folder_path=model_paths,\n",
        "          path_in_repo=trained_model,\n",
        "          repo_id=model_repo,\n",
        "          revision=revision,\n",
        "          commit_message=commit_message,\n",
        "          ignore_patterns=\".ipynb_checkpoints\"\n",
        "          )\n",
        "    print(f\"Upload success, located at https://huggingface.co/\"+model_repo+\"/tree/main\\n\")\n",
        "  else: \n",
        "    print(f\"Uploading {trained_model} to https://huggingface.co/\"+model_repo)\n",
        "    print(f\"Please wait...\")\n",
        "    if not commit_message:\n",
        "      if model_paths.endswith(\".safetensors\"):\n",
        "        commit_message = f\"feat: upload safetensors version of {trained_model} \"\n",
        "      else:\n",
        "        commit_message = f\"feat: upload {trained_model} checkpoint\"\n",
        "            \n",
        "    api.upload_file(\n",
        "        path_or_fileobj=model_paths,\n",
        "        path_in_repo=trained_model,\n",
        "        repo_id=model_repo,\n",
        "        revision=revision,\n",
        "        commit_message=commit_message,\n",
        "        )\n",
        "        \n",
        "    print(f\"Upload success, located at https://huggingface.co/\"+model_repo+\"/blob/main/\"+trained_model+\"\\n\")\n",
        "      \n",
        "def upload():\n",
        "    if model_path.endswith((\".ckpt\", \".safetensors\", \".pt\")):\n",
        "      upload_model(model_path, False, commit_message)\n",
        "    else:\n",
        "      upload_model(model_path, True, commit_message)\n",
        "\n",
        "upload()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "CIeoJA-eO-8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.3. Upload with GIT (Alternative)"
      ],
      "metadata": {
        "id": "CKZpg4keWS5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 8.3.1. Clone Repository\n",
        "%cd /content/\n",
        "clone_model = True #@param {'type': 'boolean'}\n",
        "\n",
        "!git lfs install --skip-smudge\n",
        "!export GIT_LFS_SKIP_SMUDGE=1\n",
        "\n",
        "if clone_model:\n",
        "  !git clone https://huggingface.co/{model_repo} /content/{model_name}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6nBlrOrytO9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 8.3.2. Commit using Git \n",
        "import os\n",
        "\n",
        "os.chdir(root_dir)\n",
        "\n",
        "#@markdown Choose which repo you want to commit\n",
        "commit_model = True #@param {'type': 'boolean'}\n",
        "commit_dataset = True #@param {'type': 'boolean'}\n",
        "#@markdown #### Other Information\n",
        "commit_message = \"\" #@param {type :\"string\"}\n",
        "\n",
        "if not commit_message:\n",
        "  commit_message = f\"feat: upload {model_name}\"\n",
        "\n",
        "!git config --global user.email \"example@mail.com\"\n",
        "!git config --global user.name \"example\"\n",
        "\n",
        "def commit(repo_folder, commit_message):\n",
        "  os.chdir(os.path.join(root_dir, repo_folder))\n",
        "  !git lfs install\n",
        "  !huggingface-cli lfs-enable-largefiles .\n",
        "  !git add .\n",
        "  !git commit -m \"{commit_message}\"\n",
        "  !git push\n",
        "\n",
        "commit(model_name, commit_message)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7bJev4PzOFFB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}